{
    "collab_server" : "",
    "contents" : "---\ntitle: Example script for VAST for spatio-temporal analysis of single-species catch-rate\n  data\nauthor: \"James Thorson\"\ndate: \"October 10, 2016\"\noutput:\n  pdf_document:\n    fig_caption: yes\n    number_sections: yes\n    toc: yes\n  html_document:\n    number_sections: yes\n    toc: yes\nhtml_document:\n  toc: yes\n---\n\n\n```{r set_options, echo=FALSE, message=FALSE, warning=FALSE}\n# Width should apply to tidy\n# digits hopefully affects number of digits when using print\noptions(width=50, width.cutoff=50, digits = 3) \n#install.packages(\"pander\", repos=\"http://cran.us.r-project.org\")\n```\n\n```{r wrap-hook, echo=FALSE}\n# FROM: https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd\nlibrary(knitr)\nhook_output = knit_hooks$get('output')\nknit_hooks$set(output = function(x, options) {\n  # this hook is used only when the linewidth option is not NULL\n  if (!is.null(n <- options$linewidth)) {\n    x = knitr:::split_lines(x)\n    # any lines wider than n should be wrapped\n    if (any(nchar(x) > n)) x = strwrap(x, width = n)\n    x = paste(x, collapse = '\\n')\n  }\n  hook_output(x, options)\n})\n# TRIGGERED USING `linewidth=60`\n```\n\n\n# Overview\nThis tutorial will walk through a simple example of how to use `VAST` for estimating single-species abundance indices, distribution shifts, and range expansion.\n\n# Getting started\n\nTo install TMB on a windows machine, we need to first install [Rtools](https://cran.r-project.org/bin/windows/Rtools/).  During the installation, please select the option to have Rtools included in your system path.  On other operating systems, it is not necessary to install Rtools.  We then install `VAST`  \n```{r load_packages, message=FALSE}\n# devtools::install_github(\"james-thorson/VAST\") \n# devtools::install_github(\"james-thorson/utilities\")\n```\n\nNext load libraries.\n```{r load_libraries, message=FALSE, warning=FALSE}\nlibrary(TMB)               # Can instead load library(TMBdebug)\nlibrary(VAST)\nlibrary(ThorsonUtilities)\n```\n\n## Further information\n\nIf you have further questions after reading this tutorial, please explore the [GitHub repo](https://github.com/james-thorson/VAST/#description) mainpage, wiki, and glossary.  Also please explore the R help files, e.g., `?Data_Fn` for explanation of data inputs, or `?Param_Fn` for explanation of parameters.  \n\n## Related tools\n\nRelated tools for spatio-temporal fisheries analysis are currently housed at [www.FishStats.org](http://www.FishStats.org).  These include [SpatialDeltaGLMM](https://github.com/nwfsc-assess/geostatistical_delta-GLMM/#description), a single-species antecedent of VAST, and [www.FishViz.org](http://www.FishViz.org), a tool for visualizing single-species results using worldwide. `VAST` and `SpatialDeltaGLMM` both use continuous integration to confirm that they give identical estimates when applied to single-species data.  \n\n## How to cite VAST\n\n`VAST` has involved many publications for developing individual features.  If using `VAST`, please read and cite:\n\n```{r citation, tidy=TRUE, width=70, width.cutoff=70}\ncitation(\"VAST\")\n```\n\nand also browse the [GitHub list](https://github.com/james-thorson/VAST/#description-of-package) of papers\n\n# Settings\nFirst chose an example data set for this script, as archived with package\n```{r, tidy=TRUE, linewidth=60}\nData_Set = c(\"Chatham_rise_hake\", \"Iceland_cod\", \"WCGBTS_canary\", \"GSL_american_plaice\", \"BC_pacific_cod\", \"EBS_pollock\", \"GOA_Pcod\", \"GOA_pollock\", \"GB_spring_haddock\", \"GB_fall_haddock\", \"SAWC_jacopever\", \"Aleutian_islands_POP\")[7]\n```\n\nNext use latest version for CPP code\n```{r}\nVersion = \"VAST_v2_0_0\"\n```\n\n## Spatial settings\nThe following settings define the spatial resolution for the model, and whether to use a grid or mesh approximation\n```{r}\nMethod = c(\"Grid\", \"Mesh\", \"Spherical_mesh\")[2]\ngrid_size_km = 25\nn_x = c(100, 250, 500, 1000, 2000)[1] # Number of stations\nKmeans_Config = list( \"randomseed\"=1, \"nstart\"=100, \"iter.max\"=1e3 )    \n```\n\n## Model settings\nThe following settings define whether to include spatial and spatio-temporal variation, whether its autocorrelated, and whether there's overdispersion\n```{r, tidy=TRUE}\nFieldConfig = c(\"Omega1\"=1, \"Epsilon1\"=1, \"Omega2\"=1, \"Epsilon2\"=1) \nRhoConfig = c(\"Beta1\"=0, \"Beta2\"=0, \"Epsilon1\"=0, \"Epsilon2\"=0) \nOverdispersionConfig = c(\"Delta1\"=0, \"Delta2\"=0)\nObsModel = c(1,0)  \n```\n\n## Potential outputs\nThe following settings define what types of output we want to calculate\n```{r, tidy=TRUE}\nOptions =  c(\"SD_site_density\"=0, \"SD_site_logdensity\"=0, \"Calculate_Range\"=1, \"Calculate_evenness\"=0, \"Calculate_effective_area\"=1, \"Calculate_Cov_SE\"=0, 'Calculate_Synchrony'=0, 'Calculate_Coherence'=0)\n```\n\n## Stratification for results\n\nWe also define any potential stratification of results, and settings specific to any case-study data set\n```{r define_strata, tidy=TRUE, linewidth=50}\n# Default\nif( Data_Set %in% c(\"GSL_american_plaice\",\"BC_pacific_cod\",\"EBS_pollock\",\"SAWC_jacopever\",\"Chatham_rise_hake\",\"Aleutian_islands_POP\")){\n  strata.limits <- data.frame('STRATA'=\"All_areas\")\n}\n# Specific (useful as examples)\nif( Data_Set %in% c(\"WCGBTS_canary\",\"Sim\")){\n  # In this case, it will calculate a coastwide index, and also a separate index for each state (although the state lines are approximate)\n  strata.limits <- data.frame(\n    'STRATA' = c(\"Coastwide\",\"CA\",\"OR\",\"WA\"),\n    'north_border' = c(49.0, 42.0, 46.0, 49.0),\n    'south_border' = c(32.0, 32.0, 42.0, 46.0),\n    'shallow_border' = c(55, 55, 55, 55),\n    'deep_border' = c(1280, 1280, 1280, 1280)\n  )\n  # Override default settings for vessels\n  VesselConfig = c(\"Vessel\"=0, \"VesselYear\"=1)\n}\nif( Data_Set %in% c(\"GOA_Pcod\",\"GOA_pollock\")){\n  # In this case, will calculating an unrestricted index and a separate index restricted to west of -140W\n  strata.limits <- data.frame(\n    'STRATA' = c(\"All_areas\", \"west_of_140W\"),\n    'west_border' = c(-Inf, -Inf),\n    'east_border' = c(Inf, -140)\n  )\n}\nif( Data_Set %in% c(\"GB_spring_haddock\",\"GB_fall_haddock\")){\n  # For NEFSC indices, strata must be specified as a named list of area codes\n  strata.limits = list( 'Georges_Bank'=c(1130, 1140, 1150, 1160, 1170, 1180, 1190, 1200, 1210, 1220, 1230, 1240, 1250, 1290, 1300) )\n}\nif( Data_Set %in% c(\"Iceland_cod\")){\n  strata.limits = data.frame( 'STRATA'=\"All_areas\" )\n  # Turn off all spatial, temporal, and spatio-temporal variation in probability of occurrence, because they occur almost everywhere\n  FieldConfig = c(\"Omega1\"=0, \"Epsilon1\"=0, \"Omega2\"=1, \"Epsilon2\"=1)\n  RhoConfig = c(\"Beta1\"=3, \"Beta2\"=0, \"Epsilon1\"=0, \"Epsilon2\"=0) \n}\n```\n\n## Derived objects\n\nDepending on the case study, we define a `Region` used when extrapolating or plotting density estimates.  If its a different data set, it will define `Region=\"Other\"`, and this is a recognized level for all uses of `Region` (which attempts to define reasonable settings based on the location of sampling).  For example `Data_Set=\"Iceland_cod\"` has no associated meta-data for the region, so it uses `Region=\"Other\"` by default.\n```{r define_region, tidy=FALSE}\nRegion = switch( Data_Set, \"Chatham_rise_hake\"=\"New_Zealand\", \n                 \"WCGBTS_canary\"=\"California_current\", \n                 \"GSL_american_plaice\"=\"Gulf_of_St_Lawrence\", \n                 \"BC_pacific_cod\"=\"British_Columbia\", \n                 \"EBS_pollock\"=\"Eastern_Bering_Sea\", \n                 \"GOA_Pcod\"=\"Gulf_of_Alaska\", \n                 \"GOA_pollock\"=\"Gulf_of_Alaska\", \n                 \"GB_spring_haddock\"=\"Northwest_Atlantic\", \n                 \"GB_fall_haddock\"=\"Northwest_Atlantic\", \n                 \"SAWC_jacopever\"=\"South_Africa\", \n                 \"Aleutian_islands_POP\"=\"Aleutian_Islands\",\n                 \"Other\")\n```\n\n## Save settings\n\nWe then set the location for saving files.\n```{r make_dir, message=FALSE, warning=FALSE}\nDateFile = paste0(getwd(),'/VAST_output/')\n  dir.create(DateFile)\n```\n\nI also like to save all settings for later reference, although this is not necessary.\n```{r, tidy=TRUE, linewidth=50}\nRecord = ThorsonUtilities::bundlelist( c(\"Data_Set\",\"Version\",\"Method\",\"grid_size_km\",\"n_x\",\"FieldConfig\",\"RhoConfig\",\"OverdispersionConfig\",\"ObsModel\",\"Kmeans_Config\") )\nsave( Record, file=file.path(DateFile,\"Record.RData\"))\ncapture.output( Record, file=paste0(DateFile,\"Record.txt\"))\n```\n\n# Prepare the data\n\n## Data-frame for catch-rate data\n\nDepending upon the `Data_Set` chosen, we load archived data sets that are distributed with the package. Each archived data set is then reformatted to create a data-frame `Data_Geostat` with a standardized set of columns. For a new data set, the user is responsible for formatting `Data_Geostat` appropriately to match this format.  We show the first six rows of `Data_Geostat` given that Data_Set = `Data_Set`.  \n```{r load_data, echo=FALSE, message=FALSE}\nif(Data_Set==\"WCGBTS_canary\"){\n  data( WCGBTS_Canary_example, package=\"SpatialDeltaGLMM\" )\n  Year = as.numeric(sapply(WCGBTS_Canary_example[,'PROJECT_CYCLE'], FUN=function(Char){strsplit(as.character(Char),\" \")[[1]][2]}))\n  Data_Geostat = data.frame( \"Catch_KG\"=WCGBTS_Canary_example[,'HAUL_WT_KG'], \"Year\"=Year, \"Vessel\"=WCGBTS_Canary_example[,\"VESSEL\"], \"AreaSwept_km2\"=WCGBTS_Canary_example[,\"AREA_SWEPT_HA\"]/1e2, \"Lat\"=WCGBTS_Canary_example[,'BEST_LAT_DD'], \"Lon\"=WCGBTS_Canary_example[,'BEST_LON_DD'], \"Pass\"=WCGBTS_Canary_example[,'PASS']-1.5)\n}\nif( Data_Set %in% c(\"BC_pacific_cod\")){\n  data( BC_pacific_cod_example, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=BC_pacific_cod_example[,'PCOD_WEIGHT'], \"Year\"=BC_pacific_cod_example[,'Year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=BC_pacific_cod_example[,'TOW.LENGTH..KM.']/100, \"Lat\"=BC_pacific_cod_example[,'LAT'], \"Lon\"=BC_pacific_cod_example[,'LON'], \"Pass\"=0)\n}\nif( Data_Set %in% c(\"GSL_american_plaice\")){\n  data( GSL_american_plaice, package=\"SpatialDeltaGLMM\" )\n  SpatialDeltaGLMM::Print_Message( \"GSL_american_plaice\" )\n  Data_Geostat = data.frame( \"Year\"=GSL_american_plaice[,'year'], \"Lat\"=GSL_american_plaice[,'latitude'], \"Lon\"=GSL_american_plaice[,'longitude'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=GSL_american_plaice[,'swept'], \"Catch_KG\"=GSL_american_plaice[,'biomass']*GSL_american_plaice[,'vstd'] )\n}\nif(Data_Set==\"EBS_pollock\"){\n  data( EBS_pollock_data, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=EBS_pollock_data[,'catch'], \"Year\"=EBS_pollock_data[,'year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=0.01, \"Lat\"=EBS_pollock_data[,'lat'], \"Lon\"=EBS_pollock_data[,'long'], \"Pass\"=0)\n}\nif(Data_Set==\"GOA_Pcod\"){\n  data( GOA_pacific_cod , package=\"SpatialDeltaGLMM\")\n  Data_Geostat = data.frame( \"Catch_KG\"=GOA_pacific_cod[,'catch'], \"Year\"=GOA_pacific_cod[,'year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=0.01, \"Lat\"=GOA_pacific_cod[,'lat'], \"Lon\"=GOA_pacific_cod[,'lon'], \"Pass\"=0)\n}\nif(Data_Set==\"GOA_pollock\"){\n  data( GOA_walleye_pollock, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=GOA_walleye_pollock[,'catch'], \"Year\"=GOA_walleye_pollock[,'year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=0.01, \"Lat\"=GOA_walleye_pollock[,'lat'], \"Lon\"=GOA_walleye_pollock[,'lon'], \"Pass\"=0)\n}\nif(Data_Set==\"Aleutian_islands_POP\"){\n  data( AI_pacific_ocean_perch, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=AI_pacific_ocean_perch[,'cpue..kg.km.2.'], \"Year\"=AI_pacific_ocean_perch[,'year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=1, \"Lat\"=AI_pacific_ocean_perch[,'start.latitude'], \"Lon\"=AI_pacific_ocean_perch[,'start.longitude'], \"Pass\"=0)\n}\nif( Data_Set==\"GB_spring_haddock\"){\n  data( georges_bank_haddock_spring, package=\"SpatialDeltaGLMM\" )         \n  SpatialDeltaGLMM::Print_Message( \"GB_haddock\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=georges_bank_haddock_spring[,'CATCH_WT_CAL'], \"Year\"=georges_bank_haddock_spring[,'YEAR'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=0.0112*1.852^2, \"Lat\"=georges_bank_haddock_spring[,'LATITUDE'], \"Lon\"=georges_bank_haddock_spring[,'LONGITUDE'])\n}\nif( Data_Set==\"GB_fall_haddock\"){\n  data( georges_bank_haddock_fall, package=\"SpatialDeltaGLMM\" )         \n  SpatialDeltaGLMM::Print_Message( \"GB_haddock\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=georges_bank_haddock_fall[,'CATCH_WT_CAL'], \"Year\"=georges_bank_haddock_fall[,'YEAR'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=0.0112*1.852^2, \"Lat\"=georges_bank_haddock_fall[,'LATITUDE'], \"Lon\"=georges_bank_haddock_fall[,'LONGITUDE'])\n}\nif( Data_Set==\"SAWC_jacopever\"){\n  data( south_africa_westcoast_jacopever, package=\"SpatialDeltaGLMM\" )         \n  Data_Geostat = data.frame( \"Catch_KG\"=south_africa_westcoast_jacopever[,'HELDAC'], \"Year\"=south_africa_westcoast_jacopever[,'Year'], \"Vessel\"=\"missing\", \"AreaSwept_km2\"=south_africa_westcoast_jacopever[,'area_swept_nm2']*1.852^2, \"Lat\"=south_africa_westcoast_jacopever[,'cen_lat'], \"Lon\"=south_africa_westcoast_jacopever[,'cen_long'])\n}\nif( Data_Set %in% c(\"Iceland_cod\")){\n  # WARNING:  This data set has not undergone much evaluation for spatio-temporal analysis\n  data( iceland_cod, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=iceland_cod[,'Catch_b'], \"Year\"=iceland_cod[,'year'], \"Vessel\"=1, \"AreaSwept_km2\"=iceland_cod[,'towlength'], \"Lat\"=iceland_cod[,'lat1'], \"Lon\"=iceland_cod[,'lon1'])\n}\nif( Data_Set %in% c(\"Chatham_rise_hake\")){\n  data( chatham_rise_hake, package=\"SpatialDeltaGLMM\" )\n  Data_Geostat = data.frame( \"Catch_KG\"=chatham_rise_hake[,'Hake_kg_per_km2'], \"Year\"=chatham_rise_hake[,'Year'], \"Vessel\"=1, \"AreaSwept_km2\"=1, \"Lat\"=chatham_rise_hake[,'Lat'], \"Lon\"=chatham_rise_hake[,'Lon'])\n}\nData_Geostat = na.omit( Data_Geostat )\n```\n\n```{r show_data_head, results=\"asis\", echo=FALSE}\npander::pandoc.table( Data_Geostat[1:6,], digits=3 )\n```\n\n\n## Extrapolation grid\n\nWe also generate the extrapolation grid appropriate for a given region.  For new regions, we use `Region=\"Other\"`.\n```{r extrapolation_grid, message=FALSE, tidy=TRUE, linewidth=60}\nif( Region %in% c(\"California_current\",\"Eastern_Bering_Sea\",\"Gulf_of_Alaska\",\"Aleutian_Islands\",\"Northwest_Atlantic\",\"Gulf_of_St_Lawrence\",\"New_Zealand\") ){\n  Extrapolation_List = SpatialDeltaGLMM::Prepare_Extrapolation_Data_Fn( Region=Region, strata.limits=strata.limits )\n}\nif( Region == \"British_Columbia\" ){\n  Extrapolation_List = SpatialDeltaGLMM::Prepare_Extrapolation_Data_Fn( Region=Region, strata.limits=strata.limits, strata_to_use=c(\"HS\",\"QCS\") )\n}\nif( Region == \"South_Africa\" ){\n  Extrapolation_List = SpatialDeltaGLMM::Prepare_Extrapolation_Data_Fn( Region=Region, strata.limits=strata.limits, region=\"west_coast\" )\n}\nif( Region == \"Other\" ){\n  Extrapolation_List = SpatialDeltaGLMM::Prepare_Extrapolation_Data_Fn( Region=Region, strata.limits=strata.limits, observations_LL=Data_Geostat[,c('Lat','Lon')], maximum_distance_from_sample=15 )\n}\n```\n\n## Derived objects for spatio-temporal estimation\n\nAnd we finally generate the information used for conducting spatio-temporal parameter estimation, bundled in list `Spatial_List`\n```{r spatial_information, message=FALSE, warning=FALSE, tidy=TRUE, linewidth=60}\nSpatial_List = SpatialDeltaGLMM::Spatial_Information_Fn( grid_size_km=grid_size_km, n_x=n_x, Method=Method, Lon=Data_Geostat[,'Lon'], Lat=Data_Geostat[,'Lat'], Extrapolation_List=Extrapolation_List, randomseed=Kmeans_Config[[\"randomseed\"]], nstart=Kmeans_Config[[\"nstart\"]], iter.max=Kmeans_Config[[\"iter.max\"]], DirPath=DateFile, Save_Results=FALSE )\n# Add knots to Data_Geostat\nData_Geostat = cbind( Data_Geostat, \"knot_i\"=Spatial_List$knot_i )\n```\n\n# Build and run model\n\n## Build model\n\nTo estimate parameters, we first build a list of data-inputs used for parameter estimation.  `Data_Fn` has some simple checks for buggy inputs, but also please read the help file `?Data_Fn`.  \n```{r build_data, message=FALSE, tidy=TRUE, linewidth=60}\nTmbData = Data_Fn(\"Version\"=Version, \"FieldConfig\"=FieldConfig, \"OverdispersionConfig\"=OverdispersionConfig, \"RhoConfig\"=RhoConfig, \"ObsModel\"=ObsModel, \"c_i\"=rep(0,nrow(Data_Geostat)), \"b_i\"=Data_Geostat[,'Catch_KG'], \"a_i\"=Data_Geostat[,'AreaSwept_km2'], \"v_i\"=as.numeric(Data_Geostat[,'Vessel'])-1, \"s_i\"=Data_Geostat[,'knot_i']-1, \"t_i\"=Data_Geostat[,'Year'], \"a_xl\"=Spatial_List$a_xl, \"MeshList\"=Spatial_List$MeshList, \"GridList\"=Spatial_List$GridList, \"Method\"=Spatial_List$Method, \"Options\"=Options )\n```\n\nWe then build the TMB object.\n```{r build_object, message=FALSE, results=\"hide\", tidy=TRUE}\nTmbList = Build_TMB_Fn(\"TmbData\"=TmbData, \"RunDir\"=DateFile, \"Version\"=Version, \"RhoConfig\"=RhoConfig, \"loc_x\"=Spatial_List$loc_x, \"Method\"=Method)\nObj = TmbList[[\"Obj\"]]\n```\n\n## Estimate fixed effects and predict random effects\n\nNext, we use a gradient-based nonlinear minimizer to identify maximum likelihood estimates for fixed-effects\n```{r estimate_parameters, results=\"hide\", tidy=TRUE}\nOpt = TMBhelper::Optimize( obj=Obj, lower=TmbList[[\"Lower\"]], upper=TmbList[[\"Upper\"]], getsd=TRUE, savedir=DateFile, bias.correct=FALSE )\n```\n\nFinally, we bundle and save output\n```{r save_results, linewidth=60}\nReport = Obj$report()\nSave = list(\"Opt\"=Opt, \"Report\"=Report, \"ParHat\"=Obj$env$parList(Opt$par), \"TmbData\"=TmbData)\nsave(Save, file=paste0(DateFile,\"Save.RData\"))\n```\n\n# Diagnostic plots\n\nWe first apply a set of standard model diagnostics to confirm that the model is reasonable and deserves further attention.  If any of these do not look reasonable, the model output should not be interpreted or used.\n\n## Plot data\n\nIt is always good practice to conduct exploratory analysis of data.  Here, I visualize the spatial distribution of data.  Spatio-temporal models involve the assumption that the probability of sampling a given location is statistically independent of the probability distribution for the response at that location.  So if sampling \"follows\" changes in density, then the model is probably not appropriate!\n```{r explore_data, results=\"hide\", tidy=TRUE, message=FALSE, warning=FALSE}\nSpatialDeltaGLMM::Plot_data_and_knots(Extrapolation_List=Extrapolation_List, Spatial_List=Spatial_List, Data_Geostat=Data_Geostat, PlotDir=DateFile )\n```\n![Spatial extent and location of knots](VAST_output/Data_and_knots.png) \n\n![Spatial distribution of catch-rate data](VAST_output/Data_by_year.png) \n\n## Convergence\nHere I print the diagnostics generated during parameter estimation, and I confirm that (1) no parameter is hitting an upper or lower bound and (2) the final gradient for each fixed-effect is close to zero. For explanation of parameters, please see `?Data_Fn`.\n```{r print_results, results=\"asis\"}\npander::pandoc.table( Opt$diagnostics[,c('Param','Lower','MLE','Upper','final_gradient')] ) \n```\n\n## Diagnostics for encounter-probability component\n\nNext, we check whether observed encounter frequencies for either low or high probability samples are within the 95% predictive interval for predicted encounter probability\n```{r diagnostics_encounter_prob, results=\"hide\", eval=TRUE, tidy=TRUE, linewidth=50}\nEnc_prob = SpatialDeltaGLMM::Check_encounter_prob( Report=Report, Data_Geostat=Data_Geostat, DirName=DateFile)\n```\n![Expectated probability and observed frequency of encounter for \"encounter probability\" component](VAST_output/Diag--Encounter_prob.png) \n\n\n## Diagnostics for positive-catch-rate component\n\nWe can visualize fit to residuals of catch-rates given encounters using a Q-Q plot.  A good Q-Q plot will have residuals along the one-to-one line.  \n```{r plot_QQ, eval=TRUE, tidy=TRUE, linewidth=50, message=FALSE, warning=FALSE}\nQ = SpatialDeltaGLMM::QQ_Fn( TmbData=TmbData, Report=Report, FileName_PP=paste0(DateFile,\"Posterior_Predictive.jpg\"), FileName_Phist=paste0(DateFile,\"Posterior_Predictive-Histogram.jpg\"), FileName_QQ=paste0(DateFile,\"Q-Q_plot.jpg\"), FileName_Qhist=paste0(DateFile,\"Q-Q_hist.jpg\")) # SpatialDeltaGLMM::\n```\n![Quantile-quantile plot indicating residuals for \"positive catch rate\" component](VAST_output/Q-Q_plot.jpg) \n\n## Diagnostics for plotting residuals on a map\n\nFinally, we visualize residuals on a map.  To do so, we first define years to plot and generate plotting inputs.\nuseful plots by first determining which years to plot (`Years2Include`), and labels for each plotted year (`Year_Set`)\n```{r plot_years}\n# Get region-specific settings for plots\nMapDetails_List = SpatialDeltaGLMM::MapDetails_Fn( \"Region\"=Region, \"NN_Extrap\"=Spatial_List$PolygonList$NN_Extrap, \"Extrapolation_List\"=Extrapolation_List )\n# Decide which years to plot                                                   \nYear_Set = seq(min(Data_Geostat[,'Year']),max(Data_Geostat[,'Year']))\nYears2Include = which( Year_Set %in% sort(unique(Data_Geostat[,'Year'])))\n```\n\nWe then plot Pearson residuals.  If there are visible patterns (areas with consistently positive or negative residuals accross or within years) then this is an indication of the model \"overshrinking\" results towards the intercept, and model results should then be treated with caution.  \n```{r plot_pearson_resid, message=FALSE, warning=FALSE, tidy=TRUE, linewidth=50}\nSpatialDeltaGLMM:::plot_residuals(Lat_i=Data_Geostat[,'Lat'], Lon_i=Data_Geostat[,'Lon'], TmbData=TmbData, Report=Report, Q=Q, savedir=DateFile, MappingDetails=MapDetails_List[[\"MappingDetails\"]], PlotDF=MapDetails_List[[\"PlotDF\"]], MapSizeRatio=MapDetails_List[[\"MapSizeRatio\"]], Xlim=MapDetails_List[[\"Xlim\"]], Ylim=MapDetails_List[[\"Ylim\"]], FileName=DateFile, Year_Set=Year_Set, Years2Include=Years2Include, Rotate=MapDetails_List[[\"Rotate\"]], Cex=MapDetails_List[[\"Cex\"]], Legend=MapDetails_List[[\"Legend\"]], zone=MapDetails_List[[\"Zone\"]], mar=c(0,0,2,0), oma=c(3.5,3.5,0,0), cex=1.8)\n```\n![Pearson residuals for encounter-probability by knot](VAST_output/maps--encounter_pearson_resid.png) \n\n![Pearson residuals for positive catch rates by knot](VAST_output/maps--catchrate_pearson_resid.png) \n\n\n## Model selection\n\nTo select among models, we recommend using the Akaike Information Criterion, AIC, via `Opt$AIC=` ``r Opt$AIC``. \n\n# Model output\n\nLast but not least, we generate pre-defined plots for visualizing results\n\n## Direction of \"geometric anisotropy\"\n\nWe can visualize which direction has faster or slower decorrelation (termed \"geometric anisotropy\")\n```{r plot_aniso, message=FALSE, results=\"hide\", tidy=TRUE}\nSpatialDeltaGLMM::PlotAniso_Fn( FileName=paste0(DateFile,\"Aniso.png\"), Report=Report, TmbData=TmbData )\n```\n![Decorrelation distance for different directions](VAST_output/Aniso.png) \n\n## Density surface for each year\n\nWe can visualize many types of output from the model.  Here I only show predicted density, but other options are obtained via other integers passed to `plot_set` as described in `?PlotResultsOnMap_Fn`\n```{r plot_density, message=FALSE, warning=FALSE, tidy=TRUE, linewidth=50}\nSpatialDeltaGLMM::PlotResultsOnMap_Fn(plot_set=c(3), MappingDetails=MapDetails_List[[\"MappingDetails\"]], Report=Report, Sdreport=Opt$SD, PlotDF=MapDetails_List[[\"PlotDF\"]], MapSizeRatio=MapDetails_List[[\"MapSizeRatio\"]], Xlim=MapDetails_List[[\"Xlim\"]], Ylim=MapDetails_List[[\"Ylim\"]], FileName=DateFile, Year_Set=Year_Set, Years2Include=Years2Include, Rotate=MapDetails_List[[\"Rotate\"]], Cex=MapDetails_List[[\"Cex\"]], Legend=MapDetails_List[[\"Legend\"]], zone=MapDetails_List[[\"Zone\"]], mar=c(0,0,2,0), oma=c(3.5,3.5,0,0), cex=1.8, plot_legend_fig=FALSE)\n```\n![Density maps for each year](VAST_output/Dens.png) \n\n## Index of abundance\n\nThe index of abundance is generally most useful for stock assessment models.\n```{r plot_index, message=FALSE, tidy=TRUE, linewidth=50, results=\"asis\"}\nIndex = SpatialDeltaGLMM::PlotIndex_Fn( DirName=DateFile, TmbData=TmbData, Sdreport=Opt[[\"SD\"]], Year_Set=Year_Set, Years2Include=Years2Include, use_biascorr=TRUE )\npander::pandoc.table( Index$Table[,c(\"Year\",\"Fleet\",\"Estimate_metric_tons\",\"SD_log\",\"SD_mt\")] ) \n```\n![Index of abundance plus/minus 1 standard error](VAST_output/Index.png) \n\n## Center of gravity and range expansion/contraction\n\nWe can detect shifts in distribution or range expansion/contraction.  \n```{r plot_range, message=FALSE, tidy=TRUE, linewidth=50}\nSpatialDeltaGLMM::Plot_range_shifts(Report=Report, TmbData=TmbData, Sdreport=Opt[[\"SD\"]], Znames=colnames(TmbData$Z_xm), PlotDir=DateFile, Year_Set=Year_Set)\n```\n![Center of gravity (COG) indicating shifts in distribution plus/minus 1 standard error](VAST_output/center_of_gravity.png) \n\n![Effective area occupied indicating range expansion/contraction plus/minus 1 standard error](VAST_output/Effective_Area.png) \n\n\n",
    "created" : 1490829369194.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4033285713",
    "id" : "E23369F2",
    "lastKnownWriteTime" : 1489095126,
    "last_content_update" : 1489095126,
    "path" : "//nmfs.local/AKC-ABL/Users/curry.cunningham/Desktop/GitHub/VAST/examples/VAST--single-species_example.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}